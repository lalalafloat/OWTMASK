Command Line Args: Namespace(config_file='projects/OWT-Mask/configs/mask_rcnn_R_101_FPN_LSJ_OWT.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[04/03 22:41:01 detectron2]: Rank of current process: 0. World size: 4
[04/03 22:41:03 detectron2]: Environment info:
----------------------  -------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.16 (default, Mar  2 2023, 03:21:46) [GCC 11.2.0]
numpy                   1.24.2
detectron2              0.6 @/ssd2/ltl/OWTMASK/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 10.2
detectron2 arch flags   7.0
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.9.1+cu111 @/home/ubuntu/miniconda3/envs/owtmask2/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             Tesla V100-SXM2-16GB (arch=7.0)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda
Pillow                  9.5.0
torchvision             0.10.1+cu111 @/home/ubuntu/miniconda3/envs/owtmask2/lib/python3.8/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     Not found
----------------------  -------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.1.2 (Git Hash 98be7e8afa711dc9b66c8ff3504129cb82013cdb)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.9.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[04/03 22:41:03 detectron2]: Command line arguments: Namespace(config_file='projects/OWT-Mask/configs/mask_rcnn_R_101_FPN_LSJ_OWT.yaml', dist_url='auto', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[04/03 22:41:03 detectron2]: Contents of args.config_file=projects/OWT-Mask/configs/mask_rcnn_R_101_FPN_LSJ_OWT.yaml:
MODEL:
  META_ARCHITECTURE: "OWTMASK"
#   WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-101.pkl"
  WEIGHTS: 'pretrained/model_final_f96b26.pkl'
  MASK_ON: True
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
  RESNETS:
    DEPTH: 101
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
    NORM: "SyncBN"  # BN
    # NORM: "BN"
    STRIDE_IN_1X1: True
  FPN:
    NORM: "SyncBN"  # 对齐
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  ANCHOR_GENERATOR:
    SIZES: [[32], [64], [128], [256], [512]]  # One size for each in feature map
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]  # Three aspect ratios (same for all in feature maps)
  RPN:
    IN_FEATURES: ["p2", "p3", "p4", "p5", "p6"]
    PRE_NMS_TOPK_TRAIN: 2000  # Per FPN level
    PRE_NMS_TOPK_TEST: 1000  # Per FPN level
    # Detectron1 uses 2000 proposals per-batch,
    # (See "modeling/rpn/rpn_outputs.py" for details of this legacy issue)
    # which is approximately 1000 proposals per-image since the default batch size for FPN is 2.
    POST_NMS_TOPK_TRAIN: 1000
    POST_NMS_TOPK_TEST: 1000
    CONV_DIMS: [-1, -1]  # LSJ
  ROI_HEADS:
    NAME: "ReidStandardROIHeads"
    # NAME: "StandardROIHeads"
    IN_FEATURES: ["p2", "p3", "p4", "p5"]
    NUM_CLASSES: 80
    USE_DEFORMABLE_REID_HEAD: False
  ROI_BOX_HEAD:
    NAME: "FastRCNNConvFCHead"
    NUM_FC: 1  # [LSJ] 只有一层
    POOLER_RESOLUTION: 7
    NORM: naiveSyncBN_N  # LSJ
    CONV_DIM: 256  # LSJ
    NUM_CONV: 4  # LSJ
    FC_DIM: 1024  # LSJ
  ROI_MASK_HEAD:
    NAME: "MaskRCNNConvUpsampleHead"
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    NORM: "BN"  # LSJ 猜的，但是权重完全加载了

DATASETS:
  TRAIN: ("coco_2017_train",)
  TEST: ("coco_2017_val",)
SOLVER:
  IMS_PER_BATCH: 4
  BASE_LR: 0.0002
  STEPS: (81625,122437)
  MAX_ITER: 163250
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WEIGHT_DECAY: 0.0001
  OPTIMIZER: "ADAMW"
  BACKBONE_MULTIPLIER: 0.1
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_TYPE: "full_model"
    CLIP_VALUE: 0.01
    NORM_TYPE: 2.0
  CHECKPOINT_PERIOD: 20000
INPUT:
#   MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)  # [TODO] ori maskrcnn
  SAMPLING_FRAME_NUM: 2
  # MIN_SIZE_TRAIN_SAMPLING : ["range", "choice", "range_by_clip", "choice_by_clip"]
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  # RANDOM_FLIP : ["none", "horizontal", "flip_by_clip"]. "horizontal" is set by default.
  # RANDOM_FLIP: "flip_by_clip"
  # AUGMENTATIONS: []
  MIN_SIZE_TRAIN: (320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640)
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute_range"
    SIZE: (384, 600)
  FORMAT: "RGB"
  COCO_PRETRAIN: True  # [TODO] 测试视频数据的时候改成false
  PRETRAIN_SAME_CROP: False   #if perform the same aug on key & reference frames
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 8
OUTPUT_DIR: OWTMASK_R101_LSJ_OWT_CLS80
TEST:
  DETECTIONS_PER_IMAGE: 1000
VERSION: 2

[04/03 22:41:03 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - coco_2017_val
  TRAIN:
  - coco_2017_train
GLOBAL:
  HACK: 1.0
INPUT:
  AUGMENTATIONS: []
  COCO_PRETRAIN: true
  CROP:
    ENABLED: true
    SIZE:
    - 384
    - 600
    TYPE: absolute_range
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 320
  - 352
  - 392
  - 416
  - 448
  - 480
  - 512
  - 544
  - 576
  - 608
  - 640
  MIN_SIZE_TRAIN_SAMPLING: choice
  PRETRAIN_SAME_CROP: false
  RANDOM_FLIP: horizontal
  SAMPLING_FRAME_NUM: 2
  SAMPLING_FRAME_RANGE: 10
  SAMPLING_FRAME_SHUFFLE: false
  SAMPLING_INTERVAL: 1
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
    - - 64
    - - 128
    - - 256
    - - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES:
    - res2
    - res3
    - res4
    - res5
    NORM: SyncBN
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: true
  META_ARCHITECTURE: OWTMASK
  OWTMASK:
    APPLY_CLS_THRES: 0.05
    BATCH_INFER_LEN: 10
    INFERENCE_FW: true
    INFERENCE_SELECT_THRES: 0.1
    INFERENCE_TW: true
    MEMORY_LEN: 3
    MULTI_CLS_ON: true
    TEMPORAL_SCORE_TYPE: mean
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 103.53
  - 116.28
  - 123.675
  PIXEL_STD:
  - 1.0
  - 1.0
  - 1.0
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 101
    NORM: SyncBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: naiveSyncBN_N
    NUM_CONV: 4
    NUM_FC: 1
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: ReidStandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    REID_FEAT_DIM: 256
    SCORE_THRESH_TEST: 0.05
    USE_DEFORMABLE_REID_HEAD: false
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: BN
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    - p6
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: pretrained/model_final_f96b26.pkl
OUTPUT_DIR: OWTMASK_R101_LSJ_OWT_CLS80
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 20000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 163250
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 81625
  - 122437
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 10
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 1000
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[04/03 22:41:03 detectron2]: Full config saved to OWTMASK_R101_LSJ_OWT_CLS80/config.yaml
[04/03 22:41:03 d2.utils.env]: Using a generated random seed 4056346
[04/03 22:41:05 d2.engine.defaults]: Model:
OWTMASK(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (6): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (7): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (8): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (9): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (10): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (11): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (12): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (13): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (14): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (15): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (16): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (17): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (18): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (19): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (20): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (21): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (22): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Sequential(
        (conv0): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
        (conv1): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
          (activation): ReLU()
        )
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): ReidStandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (conv1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
      )
      (conv2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
      )
      (conv3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
      )
      (conv4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): NaiveSyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
      )
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
    )
    (box_predictor): ReidFastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (reid_embed_head): MLP(
        (layers): ModuleList(
          (0): Linear(in_features=1024, out_features=256, bias=True)
          (1): Linear(in_features=256, out_features=256, bias=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
        )
      )
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[04/03 22:41:05 d2.projects.owtmask.data.coco_clip]: TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640), max_size=1333, sample_style='choice')]
[04/03 22:41:05 d2.projects.owtmask.data.coco_clip]: Full TransformGens used in training: [RandomFlip(), ResizeShortestEdge(short_edge_length=(320, 352, 392, 416, 448, 480, 512, 544, 576, 608, 640), max_size=1333, sample_style='choice')], crop: [ResizeShortestEdge(short_edge_length=[400, 500, 600], sample_style='choice'), RandomCrop(crop_type='absolute_range', crop_size=[384, 600])]
[04/03 22:41:21 d2.data.datasets.coco]: Loading datasets/coco/annotations/instances_train2017.json takes 15.81 seconds.
[04/03 22:41:22 d2.data.datasets.coco]: Loaded 118287 images in COCO format from datasets/coco/annotations/instances_train2017.json
[04/03 22:41:29 d2.projects.owtmask.data.build]: Removed 1021 images with no usable annotations. 117266 images left.
[04/03 22:41:29 d2.projects.owtmask.data.build]: Using training sampler TrainingSampler
[04/03 22:41:31 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[04/03 22:41:31 d2.data.common]: Serializing 117266 elements to byte tensors and concatenating them all ...
[04/03 22:41:34 d2.data.common]: Serialized dataset takes 451.21 MiB
[04/03 22:41:37 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from pretrained/model_final_f96b26.pkl ...
[04/03 22:41:37 fvcore.common.checkpoint]: [Checkpointer] Loading from pretrained/model_final_f96b26.pkl ...
[04/03 22:41:37 fvcore.common.checkpoint]: Reading a file from 'Detectron2 Model Zoo'
WARNING [04/03 22:41:37 fvcore.common.checkpoint]: Some model parameters or buffers are not found in the checkpoint:
roi_heads.box_predictor.reid_embed_head.layers.0.{bias, weight}
roi_heads.box_predictor.reid_embed_head.layers.1.{bias, weight}
roi_heads.box_predictor.reid_embed_head.layers.2.{bias, weight}
WARNING [04/03 22:41:37 fvcore.common.checkpoint]: The checkpoint state_dict contains keys that are not used by the model:
  backbone.bottom_up.stem.conv1.norm.num_batches_tracked
  backbone.bottom_up.res2.0.shortcut.norm.num_batches_tracked
  backbone.bottom_up.res2.0.conv1.norm.num_batches_tracked
  backbone.bottom_up.res2.0.conv2.norm.num_batches_tracked
  backbone.bottom_up.res2.0.conv3.norm.num_batches_tracked
  backbone.bottom_up.res2.1.conv1.norm.num_batches_tracked
  backbone.bottom_up.res2.1.conv2.norm.num_batches_tracked
  backbone.bottom_up.res2.1.conv3.norm.num_batches_tracked
  backbone.bottom_up.res2.2.conv1.norm.num_batches_tracked
  backbone.bottom_up.res2.2.conv2.norm.num_batches_tracked
  backbone.bottom_up.res2.2.conv3.norm.num_batches_tracked
[04/03 22:41:37 d2.engine.train_loop]: Starting training from iteration 0
[04/03 22:42:01 d2.utils.events]:  eta: 19:04:50  iter: 19  total_loss: 5.497  loss_cls: 0.3171  loss_box_reg: 0.2353  loss_co: 4.199  loss_aux: 0.1551  loss_mask: 0.3082  loss_rpn_cls: 0.09556  loss_rpn_loc: 0.1028  time: 0.4349  last_time: 0.4057  data_time: 0.7312  last_data_time: 0.0080   lr: 2e-05  max_mem: 6430M
[04/03 22:42:10 d2.utils.events]:  eta: 18:45:49  iter: 39  total_loss: 4.638  loss_cls: 0.2727  loss_box_reg: 0.1581  loss_co: 3.503  loss_aux: 0.1011  loss_mask: 0.275  loss_rpn_cls: 0.05997  loss_rpn_loc: 0.07906  time: 0.4214  last_time: 0.3756  data_time: 0.0077  last_data_time: 0.0062   lr: 2e-05  max_mem: 6430M
[04/03 22:42:18 d2.utils.events]:  eta: 18:43:39  iter: 59  total_loss: 4.596  loss_cls: 0.2452  loss_box_reg: 0.1722  loss_co: 3.561  loss_aux: 0.1006  loss_mask: 0.315  loss_rpn_cls: 0.05087  loss_rpn_loc: 0.04375  time: 0.4195  last_time: 0.5187  data_time: 0.0079  last_data_time: 0.0067   lr: 2e-05  max_mem: 6497M
debug: train, pairs = 0
[04/03 22:42:26 d2.utils.events]:  eta: 18:48:18  iter: 79  total_loss: 4.769  loss_cls: 0.2755  loss_box_reg: 0.2404  loss_co: 3.646  loss_aux: 0.1052  loss_mask: 0.2578  loss_rpn_cls: 0.06233  loss_rpn_loc: 0.07487  time: 0.4220  last_time: 0.4363  data_time: 0.0085  last_data_time: 0.0116   lr: 2e-05  max_mem: 7359M
[04/03 22:42:35 d2.utils.events]:  eta: 18:48:03  iter: 99  total_loss: 4.737  loss_cls: 0.27  loss_box_reg: 0.2306  loss_co: 3.599  loss_aux: 0.09674  loss_mask: 0.2804  loss_rpn_cls: 0.05498  loss_rpn_loc: 0.08321  time: 0.4207  last_time: 0.3736  data_time: 0.0077  last_data_time: 0.0102   lr: 2e-05  max_mem: 7359M
[04/03 22:42:43 d2.utils.events]:  eta: 18:52:43  iter: 119  total_loss: 4.567  loss_cls: 0.299  loss_box_reg: 0.2469  loss_co: 3.446  loss_aux: 0.08175  loss_mask: 0.2989  loss_rpn_cls: 0.06102  loss_rpn_loc: 0.08715  time: 0.4206  last_time: 0.4017  data_time: 0.0082  last_data_time: 0.0055   lr: 2e-05  max_mem: 7359M
[04/03 22:42:52 d2.utils.events]:  eta: 18:49:37  iter: 139  total_loss: 4.515  loss_cls: 0.2856  loss_box_reg: 0.2373  loss_co: 3.531  loss_aux: 0.08825  loss_mask: 0.2877  loss_rpn_cls: 0.05014  loss_rpn_loc: 0.07259  time: 0.4200  last_time: 0.4040  data_time: 0.0067  last_data_time: 0.0076   lr: 2e-05  max_mem: 7359M
[04/03 22:43:00 d2.utils.events]:  eta: 18:45:46  iter: 159  total_loss: 4.503  loss_cls: 0.2747  loss_box_reg: 0.2069  loss_co: 3.527  loss_aux: 0.08735  loss_mask: 0.2875  loss_rpn_cls: 0.07164  loss_rpn_loc: 0.0785  time: 0.4188  last_time: 0.4312  data_time: 0.0079  last_data_time: 0.0052   lr: 2e-05  max_mem: 7359M
[04/03 22:43:08 d2.utils.events]:  eta: 18:45:12  iter: 179  total_loss: 4.373  loss_cls: 0.2566  loss_box_reg: 0.2404  loss_co: 3.342  loss_aux: 0.07873  loss_mask: 0.2735  loss_rpn_cls: 0.06361  loss_rpn_loc: 0.0698  time: 0.4180  last_time: 0.4595  data_time: 0.0075  last_data_time: 0.0062   lr: 2e-05  max_mem: 7359M
[04/03 22:43:16 d2.utils.events]:  eta: 18:45:03  iter: 199  total_loss: 4.302  loss_cls: 0.2146  loss_box_reg: 0.1788  loss_co: 3.411  loss_aux: 0.07165  loss_mask: 0.2313  loss_rpn_cls: 0.05223  loss_rpn_loc: 0.04649  time: 0.4173  last_time: 0.4188  data_time: 0.0069  last_data_time: 0.0055   lr: 2e-05  max_mem: 7359M
debug: train, pairs = 0
[04/03 22:43:25 d2.utils.events]:  eta: 18:45:21  iter: 219  total_loss: 4.205  loss_cls: 0.2399  loss_box_reg: 0.2041  loss_co: 3.29  loss_aux: 0.07288  loss_mask: 0.2492  loss_rpn_cls: 0.05887  loss_rpn_loc: 0.08717  time: 0.4183  last_time: 0.4006  data_time: 0.0082  last_data_time: 0.0114   lr: 2e-05  max_mem: 7359M
[04/03 22:43:33 d2.utils.events]:  eta: 18:52:11  iter: 239  total_loss: 4.398  loss_cls: 0.275  loss_box_reg: 0.2661  loss_co: 3.375  loss_aux: 0.07322  loss_mask: 0.263  loss_rpn_cls: 0.06145  loss_rpn_loc: 0.05206  time: 0.4193  last_time: 0.4228  data_time: 0.0087  last_data_time: 0.0055   lr: 2e-05  max_mem: 7359M
[04/03 22:43:42 d2.utils.events]:  eta: 18:56:07  iter: 259  total_loss: 4.117  loss_cls: 0.2533  loss_box_reg: 0.2108  loss_co: 3.134  loss_aux: 0.06616  loss_mask: 0.2335  loss_rpn_cls: 0.06075  loss_rpn_loc: 0.0989  time: 0.4199  last_time: 0.3907  data_time: 0.0098  last_data_time: 0.0099   lr: 2e-05  max_mem: 7359M
[04/03 22:43:50 d2.utils.events]:  eta: 18:57:09  iter: 279  total_loss: 3.997  loss_cls: 0.2309  loss_box_reg: 0.1936  loss_co: 3.168  loss_aux: 0.06295  loss_mask: 0.2578  loss_rpn_cls: 0.05825  loss_rpn_loc: 0.05624  time: 0.4200  last_time: 0.4050  data_time: 0.0076  last_data_time: 0.0079   lr: 2e-05  max_mem: 7359M
[04/03 22:43:59 d2.utils.events]:  eta: 18:55:39  iter: 299  total_loss: 4.297  loss_cls: 0.2805  loss_box_reg: 0.2368  loss_co: 3.184  loss_aux: 0.07219  loss_mask: 0.2982  loss_rpn_cls: 0.0611  loss_rpn_loc: 0.1057  time: 0.4192  last_time: 0.3814  data_time: 0.0066  last_data_time: 0.0075   lr: 2e-05  max_mem: 7359M
[04/03 22:44:07 d2.utils.events]:  eta: 18:55:14  iter: 319  total_loss: 4.259  loss_cls: 0.2515  loss_box_reg: 0.2215  loss_co: 3.236  loss_aux: 0.07026  loss_mask: 0.267  loss_rpn_cls: 0.06681  loss_rpn_loc: 0.09829  time: 0.4187  last_time: 0.4155  data_time: 0.0087  last_data_time: 0.0105   lr: 2e-05  max_mem: 7359M
debug: train, pairs = 0
[04/03 22:44:15 d2.utils.events]:  eta: 18:55:22  iter: 339  total_loss: 4.222  loss_cls: 0.3246  loss_box_reg: 0.2462  loss_co: 3.137  loss_aux: 0.0662  loss_mask: 0.3006  loss_rpn_cls: 0.06021  loss_rpn_loc: 0.1046  time: 0.4190  last_time: 0.4501  data_time: 0.0098  last_data_time: 0.0132   lr: 2e-05  max_mem: 7359M
[04/03 22:44:24 d2.utils.events]:  eta: 18:55:26  iter: 359  total_loss: 4.195  loss_cls: 0.2709  loss_box_reg: 0.2393  loss_co: 3.165  loss_aux: 0.0659  loss_mask: 0.2606  loss_rpn_cls: 0.06209  loss_rpn_loc: 0.08154  time: 0.4193  last_time: 0.4127  data_time: 0.0069  last_data_time: 0.0056   lr: 2e-05  max_mem: 7359M
[04/03 22:44:32 d2.utils.events]:  eta: 18:55:46  iter: 379  total_loss: 4.336  loss_cls: 0.2562  loss_box_reg: 0.1947  loss_co: 3.265  loss_aux: 0.05892  loss_mask: 0.2607  loss_rpn_cls: 0.03166  loss_rpn_loc: 0.05142  time: 0.4194  last_time: 0.4264  data_time: 0.0081  last_data_time: 0.0081   lr: 2e-05  max_mem: 7359M
[04/03 22:44:41 d2.utils.events]:  eta: 18:54:05  iter: 399  total_loss: 4.444  loss_cls: 0.2714  loss_box_reg: 0.1924  loss_co: 3.451  loss_aux: 0.06361  loss_mask: 0.2775  loss_rpn_cls: 0.05193  loss_rpn_loc: 0.04241  time: 0.4189  last_time: 0.3909  data_time: 0.0076  last_data_time: 0.0047   lr: 2e-05  max_mem: 7359M
[04/03 22:44:49 d2.utils.events]:  eta: 18:53:57  iter: 419  total_loss: 4.161  loss_cls: 0.2704  loss_box_reg: 0.2346  loss_co: 3.171  loss_aux: 0.06687  loss_mask: 0.2792  loss_rpn_cls: 0.05501  loss_rpn_loc: 0.07689  time: 0.4193  last_time: 0.5480  data_time: 0.0080  last_data_time: 0.0056   lr: 2e-05  max_mem: 7359M
[04/03 22:44:58 d2.utils.events]:  eta: 18:53:49  iter: 439  total_loss: 4.292  loss_cls: 0.2942  loss_box_reg: 0.2196  loss_co: 3.265  loss_aux: 0.06895  loss_mask: 0.2675  loss_rpn_cls: 0.05467  loss_rpn_loc: 0.0843  time: 0.4193  last_time: 0.4738  data_time: 0.0075  last_data_time: 0.0059   lr: 2e-05  max_mem: 7359M
[04/03 22:45:06 d2.utils.events]:  eta: 18:53:40  iter: 459  total_loss: 4.323  loss_cls: 0.3124  loss_box_reg: 0.2564  loss_co: 3.356  loss_aux: 0.05801  loss_mask: 0.2883  loss_rpn_cls: 0.05317  loss_rpn_loc: 0.1011  time: 0.4192  last_time: 0.4031  data_time: 0.0087  last_data_time: 0.0074   lr: 2e-05  max_mem: 7359M
[04/03 22:45:15 d2.utils.events]:  eta: 18:54:07  iter: 479  total_loss: 4.274  loss_cls: 0.2336  loss_box_reg: 0.1966  loss_co: 3.3  loss_aux: 0.06221  loss_mask: 0.2733  loss_rpn_cls: 0.04087  loss_rpn_loc: 0.04155  time: 0.4196  last_time: 0.4557  data_time: 0.0090  last_data_time: 0.0096   lr: 2e-05  max_mem: 7359M
[04/03 22:45:23 d2.utils.events]:  eta: 18:54:27  iter: 499  total_loss: 4.264  loss_cls: 0.2708  loss_box_reg: 0.2466  loss_co: 3.312  loss_aux: 0.06127  loss_mask: 0.2443  loss_rpn_cls: 0.04678  loss_rpn_loc: 0.04861  time: 0.4199  last_time: 0.4271  data_time: 0.0077  last_data_time: 0.0073   lr: 2e-05  max_mem: 7359M
[04/03 22:45:31 d2.utils.events]:  eta: 18:54:19  iter: 519  total_loss: 4.153  loss_cls: 0.2696  loss_box_reg: 0.2102  loss_co: 3.15  loss_aux: 0.05746  loss_mask: 0.2688  loss_rpn_cls: 0.06647  loss_rpn_loc: 0.07208  time: 0.4198  last_time: 0.3875  data_time: 0.0072  last_data_time: 0.0051   lr: 2e-05  max_mem: 7359M
[04/03 22:45:40 d2.utils.events]:  eta: 18:53:07  iter: 539  total_loss: 4.175  loss_cls: 0.303  loss_box_reg: 0.2175  loss_co: 3.223  loss_aux: 0.05998  loss_mask: 0.2754  loss_rpn_cls: 0.05836  loss_rpn_loc: 0.05405  time: 0.4195  last_time: 0.3886  data_time: 0.0070  last_data_time: 0.0080   lr: 2e-05  max_mem: 7359M
[04/03 22:45:48 d2.utils.events]:  eta: 18:52:59  iter: 559  total_loss: 4.195  loss_cls: 0.2392  loss_box_reg: 0.2292  loss_co: 3.19  loss_aux: 0.06571  loss_mask: 0.2795  loss_rpn_cls: 0.05652  loss_rpn_loc: 0.1166  time: 0.4194  last_time: 0.3881  data_time: 0.0089  last_data_time: 0.0073   lr: 2e-05  max_mem: 7359M
[04/03 22:45:56 d2.utils.events]:  eta: 18:52:23  iter: 579  total_loss: 4.265  loss_cls: 0.2629  loss_box_reg: 0.2046  loss_co: 3.282  loss_aux: 0.05983  loss_mask: 0.2992  loss_rpn_cls: 0.06845  loss_rpn_loc: 0.07962  time: 0.4193  last_time: 0.3785  data_time: 0.0068  last_data_time: 0.0084   lr: 2e-05  max_mem: 7359M
[04/03 22:46:05 d2.utils.events]:  eta: 18:52:15  iter: 599  total_loss: 4.24  loss_cls: 0.2148  loss_box_reg: 0.1964  loss_co: 3.186  loss_aux: 0.06044  loss_mask: 0.2524  loss_rpn_cls: 0.06397  loss_rpn_loc: 0.1273  time: 0.4193  last_time: 0.4368  data_time: 0.0086  last_data_time: 0.0084   lr: 2e-05  max_mem: 7359M
[04/03 22:46:13 d2.utils.events]:  eta: 18:51:47  iter: 619  total_loss: 4.165  loss_cls: 0.2398  loss_box_reg: 0.2222  loss_co: 3.153  loss_aux: 0.06406  loss_mask: 0.2645  loss_rpn_cls: 0.04797  loss_rpn_loc: 0.0772  time: 0.4190  last_time: 0.4649  data_time: 0.0083  last_data_time: 0.0084   lr: 2e-05  max_mem: 7359M
[04/03 22:46:21 d2.utils.events]:  eta: 18:50:32  iter: 639  total_loss: 3.972  loss_cls: 0.2419  loss_box_reg: 0.2137  loss_co: 3.058  loss_aux: 0.05667  loss_mask: 0.2596  loss_rpn_cls: 0.05078  loss_rpn_loc: 0.08151  time: 0.4187  last_time: 0.4271  data_time: 0.0083  last_data_time: 0.0083   lr: 2e-05  max_mem: 7359M
[04/03 22:46:29 d2.utils.events]:  eta: 18:49:33  iter: 659  total_loss: 4.217  loss_cls: 0.2654  loss_box_reg: 0.2232  loss_co: 3.126  loss_aux: 0.06088  loss_mask: 0.2781  loss_rpn_cls: 0.06078  loss_rpn_loc: 0.09722  time: 0.4185  last_time: 0.4115  data_time: 0.0079  last_data_time: 0.0068   lr: 2e-05  max_mem: 7359M
[04/03 22:46:38 d2.utils.events]:  eta: 18:49:05  iter: 679  total_loss: 4.116  loss_cls: 0.2866  loss_box_reg: 0.2252  loss_co: 3.163  loss_aux: 0.06031  loss_mask: 0.2671  loss_rpn_cls: 0.04913  loss_rpn_loc: 0.06784  time: 0.4181  last_time: 0.3893  data_time: 0.0075  last_data_time: 0.0064   lr: 2e-05  max_mem: 7359M
[04/03 22:46:46 d2.utils.events]:  eta: 18:49:16  iter: 699  total_loss: 4.036  loss_cls: 0.2469  loss_box_reg: 0.2165  loss_co: 3.127  loss_aux: 0.0551  loss_mask: 0.2573  loss_rpn_cls: 0.04787  loss_rpn_loc: 0.0606  time: 0.4183  last_time: 0.4289  data_time: 0.0087  last_data_time: 0.0060   lr: 2e-05  max_mem: 7359M
[04/03 22:46:55 d2.utils.events]:  eta: 18:49:58  iter: 719  total_loss: 4.222  loss_cls: 0.2396  loss_box_reg: 0.2301  loss_co: 3.263  loss_aux: 0.05732  loss_mask: 0.2546  loss_rpn_cls: 0.05159  loss_rpn_loc: 0.09553  time: 0.4184  last_time: 0.4133  data_time: 0.0079  last_data_time: 0.0044   lr: 2e-05  max_mem: 7359M
[04/03 22:47:03 d2.utils.events]:  eta: 18:49:00  iter: 739  total_loss: 3.995  loss_cls: 0.2412  loss_box_reg: 0.1903  loss_co: 3.209  loss_aux: 0.06073  loss_mask: 0.2611  loss_rpn_cls: 0.04756  loss_rpn_loc: 0.05439  time: 0.4181  last_time: 0.3902  data_time: 0.0076  last_data_time: 0.0070   lr: 2e-05  max_mem: 7359M
[04/03 22:47:11 d2.utils.events]:  eta: 18:50:16  iter: 759  total_loss: 4.016  loss_cls: 0.2717  loss_box_reg: 0.2249  loss_co: 3.145  loss_aux: 0.06205  loss_mask: 0.2685  loss_rpn_cls: 0.05497  loss_rpn_loc: 0.0842  time: 0.4184  last_time: 0.4696  data_time: 0.0078  last_data_time: 0.0058   lr: 2e-05  max_mem: 7359M
[04/03 22:47:20 d2.utils.events]:  eta: 18:48:41  iter: 779  total_loss: 4.322  loss_cls: 0.2667  loss_box_reg: 0.2164  loss_co: 3.233  loss_aux: 0.05884  loss_mask: 0.2777  loss_rpn_cls: 0.0625  loss_rpn_loc: 0.08693  time: 0.4181  last_time: 0.3658  data_time: 0.0080  last_data_time: 0.0085   lr: 2e-05  max_mem: 7359M
[04/03 22:47:28 d2.utils.events]:  eta: 18:48:15  iter: 799  total_loss: 4.111  loss_cls: 0.2828  loss_box_reg: 0.2084  loss_co: 3.176  loss_aux: 0.06123  loss_mask: 0.2528  loss_rpn_cls: 0.06742  loss_rpn_loc: 0.08334  time: 0.4180  last_time: 0.4516  data_time: 0.0088  last_data_time: 0.0065   lr: 2e-05  max_mem: 7359M
[04/03 22:47:36 d2.utils.events]:  eta: 18:48:24  iter: 819  total_loss: 4.033  loss_cls: 0.2412  loss_box_reg: 0.2053  loss_co: 3.11  loss_aux: 0.05749  loss_mask: 0.2486  loss_rpn_cls: 0.05996  loss_rpn_loc: 0.09782  time: 0.4181  last_time: 0.4225  data_time: 0.0091  last_data_time: 0.0046   lr: 2e-05  max_mem: 7359M
debug: train, pairs = 0
[04/03 22:47:45 d2.utils.events]:  eta: 18:48:16  iter: 839  total_loss: 4.101  loss_cls: 0.244  loss_box_reg: 0.2132  loss_co: 3.231  loss_aux: 0.06014  loss_mask: 0.2409  loss_rpn_cls: 0.0482  loss_rpn_loc: 0.1044  time: 0.4182  last_time: 0.4250  data_time: 0.0074  last_data_time: 0.0044   lr: 2e-05  max_mem: 7359M
[04/03 22:47:53 d2.utils.events]:  eta: 18:49:00  iter: 859  total_loss: 4.267  loss_cls: 0.3178  loss_box_reg: 0.284  loss_co: 3.103  loss_aux: 0.06185  loss_mask: 0.2561  loss_rpn_cls: 0.07188  loss_rpn_loc: 0.1046  time: 0.4184  last_time: 0.4576  data_time: 0.0095  last_data_time: 0.0091   lr: 2e-05  max_mem: 7359M
[04/03 22:48:02 d2.utils.events]:  eta: 18:49:05  iter: 879  total_loss: 4.074  loss_cls: 0.2263  loss_box_reg: 0.2334  loss_co: 3.135  loss_aux: 0.05352  loss_mask: 0.2656  loss_rpn_cls: 0.05756  loss_rpn_loc: 0.07671  time: 0.4185  last_time: 0.4038  data_time: 0.0082  last_data_time: 0.0055   lr: 2e-05  max_mem: 7359M
debug: train, pairs = 0
[04/03 22:48:10 d2.utils.events]:  eta: 18:48:43  iter: 899  total_loss: 3.957  loss_cls: 0.2344  loss_box_reg: 0.2059  loss_co: 3.013  loss_aux: 0.0538  loss_mask: 0.2311  loss_rpn_cls: 0.06761  loss_rpn_loc: 0.08588  time: 0.4185  last_time: 0.4320  data_time: 0.0080  last_data_time: 0.0071   lr: 2e-05  max_mem: 7359M
[04/03 22:48:18 d2.utils.events]:  eta: 18:47:42  iter: 919  total_loss: 4.043  loss_cls: 0.2416  loss_box_reg: 0.2243  loss_co: 3.106  loss_aux: 0.06035  loss_mask: 0.2687  loss_rpn_cls: 0.06274  loss_rpn_loc: 0.112  time: 0.4182  last_time: 0.4500  data_time: 0.0081  last_data_time: 0.0055   lr: 2e-05  max_mem: 7359M
Traceback (most recent call last):
  File "projects/OWT-Mask/train_net.py", line 269, in <module>
    launch(
  File "/ssd2/ltl/OWTMASK/detectron2/engine/launch.py", line 69, in launch
    mp.start_processes(
  File "/home/ubuntu/miniconda3/envs/owtmask2/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 188, in start_processes
    while not context.join():
  File "/home/ubuntu/miniconda3/envs/owtmask2/lib/python3.8/site-packages/torch/multiprocessing/spawn.py", line 130, in join
    raise ProcessExitedException(
torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGKILL
/home/ubuntu/miniconda3/envs/owtmask2/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 128 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
